# HLX Compiler

**Deterministic GPU execution via Vulkan/SPIR-V**

[![Tests](https://img.shields.io/badge/tests-passing-brightgreen)]()
[![License](https://img.shields.io/badge/license-Apache%202.0-blue)]()
[![Status](https://img.shields.io/badge/status-production%20ready-green)]()

---

## Quick Start

```bash
# Install (one command)
./install.sh

# Run benchmark
./target/release/train_transformer_full

# Expected: 0.4783 final loss (6.7% better than CUDA's 0.5128)
```

**Full instructions:** [QUICKSTART.md](QUICKSTART.md)

---

## What Is This?

HLX is an open-source language and compiler that achieves **deterministic, high-performance GPU execution** using Vulkan/SPIR-V.

**Key Results:**
- âœ… **6.7% better than CUDA** on transformer training (0.4783 vs 0.5128 loss)
- âœ… **100% reproducible** (bit-exact across runs and hardware)
- âœ… **Cross-vendor** (works on AMD, NVIDIA, Intel via pure Vulkan)
- âœ… **Open standards** (no vendor lock-in, no proprietary APIs)

---

## For AMD

See **[README_AMD.md](README_AMD.md)** for:
- Complete technical overview
- Benchmark methodology
- Architecture deep-dive
- Collaboration opportunities
- Integration strategies

**TL;DR:** HLX proves deterministic GPU compute is viable today using open standards (Vulkan/SPIR-V). Built on AMD's strategic investments (ROCm, MLIR, Vulkan).

---

## Documentation

| Document | Description |
|----------|-------------|
| **[QUICKSTART.md](QUICKSTART.md)** | 5-minute getting started guide |
| **[README_AMD.md](README_AMD.md)** | Complete technical overview for AMD |
| **[benchmarks/BENCHMARK_RESULTS.md](benchmarks/BENCHMARK_RESULTS.md)** | Detailed benchmark analysis |
| **[examples/](examples/)** | Example programs (hello world, matrix multiply) |
| **[docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)** | System architecture |
| **[docs/CONTRACTS.md](docs/CONTRACTS.md)** | Contract specifications |

---

## Repository Structure

```
hlx-compiler/
â”œâ”€â”€ install.sh              # One-command installer
â”œâ”€â”€ QUICKSTART.md           # 5-minute setup
â”œâ”€â”€ README_AMD.md           # Technical overview for AMD
â”‚
â”œâ”€â”€ runtime/                # HLX language runtimes
â”‚   â””â”€â”€ hlx_runtime/        # 4 runtimes, 3 wire formats, 433 tests
â”‚
â”œâ”€â”€ src/                    # Rust compiler source
â”‚   â”œâ”€â”€ lib.rs              # Vulkan context
â”‚   â””â”€â”€ bin/                # Training binaries
â”‚       â””â”€â”€ train_transformer_full.rs
â”‚
â”œâ”€â”€ shader/                 # GLSL compute shaders
â”‚   â”œâ”€â”€ gemm.glsl
â”‚   â”œâ”€â”€ layernorm.glsl
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ benchmarks/             # Benchmark data
â”‚   â”œâ”€â”€ BENCHMARK_RESULTS.md
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ cuda_results.json    # CUDA baseline
â”‚       â””â”€â”€ training_curve.csv   # HLX results
â”‚
â””â”€â”€ examples/               # Example programs
    â”œâ”€â”€ hello_world.hlxl
    â””â”€â”€ matrix_multiply.hlxl
```

---

## Benchmark Summary

| Metric | HLX (Vulkan) | PyTorch (CUDA) | Winner |
|--------|--------------|----------------|--------|
| **Final Loss** | **0.4783** | 0.5128 | **HLX (6.7% better)** |
| **Reproducibility** | **100% (bit-exact)** | ~95% | **HLX** |
| **Hardware Support** | AMD + NVIDIA + Intel | NVIDIA only | **HLX** |

Full analysis: [benchmarks/BENCHMARK_RESULTS.md](benchmarks/BENCHMARK_RESULTS.md)

---

## Why It Matters

**For Developers:**
- Write once, run on any GPU (AMD, NVIDIA, Intel)
- Guaranteed reproducible results
- No kernel programming required

**For AMD:**
- Validates Vulkan/SPIR-V for ML workloads
- Enables "reproducible AI on AMD" narrative
- Provides reference implementation for ROCm integration

**For Science:**
- Reproducible ML experiments
- Auditable computation
- Cross-platform validation

---

## Quick Links

- ğŸš€ **[Get Started](QUICKSTART.md)** - Install and run in 5 minutes
- ğŸ“Š **[Benchmarks](benchmarks/BENCHMARK_RESULTS.md)** - Detailed performance analysis
- ğŸ¢ **[For AMD](README_AMD.md)** - Technical overview and collaboration
- ğŸ“ **[Examples](examples/)** - Sample programs
- ğŸ’¬ **[Contact](mailto:latentcollapse@gmail.com)** - Questions or feedback

---

## License

Apache 2.0 - Open Source

## Author

Matt Cohn ([@latentcollapse](https://github.com/latentcollapse))

Independent developer committed to open, reproducible, cross-vendor GPU compute.

---

**Built with â¤ï¸ for deterministic computation**
